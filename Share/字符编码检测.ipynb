{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# change the cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**版本说明**\n",
    "\n",
    "* Python 3.x\n",
    "* chardet 3.0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字符编码检测\n",
    "在处理文本数据的过程中，经常会遇到因使用的字符编码不正确而导致数据不能进行数据处理。为了解决这个问题，可以先检测出文本数据的编码方式，之后再采用相应的解码方式来读取数据。这里可以通过 `chardet` 包来完成检测编码类型的工作。可以检查的编码类型为：\n",
    "\n",
    "* Big5, GB2312/GB18030, EUC-TW, HZ-GB-2312, ISO-2022-CN (繁简中文字体)\n",
    "* EUC-JP, SHIFT_JIS, ISO-2022-JP (日文字体)\n",
    "* EUC-KR , ISO-2022-KR (韩文字体)\n",
    "* KOI8-R, MacCyrillic, IBM855, IBM866, ISO-8859-5, windows-1251 (俄文字体)\n",
    "* ISO-8859-2 , windows-1250 (匈牙利字体)\n",
    "* ISO-8859-5 , windows-1251 (保加利亚字体)\n",
    "* ISO-8859-1 , windows-1252 (西欧语言字体)\n",
    "* ISO-8859-7 , windows-1253 (希腊字体)\n",
    "* ISO-8859-8 , windows-1255 (Visual , Logical Hebrew)\n",
    "* TIS-620 (泰文字体)\n",
    "* UTF-32 BE, LE, 3412-ordered, or 2143-ordered (with a BOM)\n",
    "* UTF-16 BE or LE (with a BOM)\n",
    "* UTF-8 (with or without a BOM)\n",
    "* ASCII\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'³o\\xadÓ»y¥y¬O¥Î©ó´ú¸Õªº»y¥y'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 解码不正确\n",
    "'這個語句是用於測試的語句'.encode('Big5').decode(\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Cette phrase est la d\\xe9claration utilis\\xe9e pour tester'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Cette phrase est la déclaration utilisée pour tester\".encode(\"windows-1252\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "from chardet.universaldetector import UniversalDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chardet version is: 3.0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Chardet version is:\", chardet.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用的检测方法\n",
    "使用的检测方法包括了，`detect()` 方法和 `UniversalDetector` 类。其中 chardet 中的 detect 方法，可以用于检测二进制文件的编码类型。此外得到的結果可以对应数据内容的编码方式，推测置信水平以及推测的语言：\n",
    "\n",
    "```\n",
    "{'encoding': 'EUC-JP', 'confidence': 0.99, 'language': 'Japanese'}\n",
    "```\n",
    "之后使用字符串的 `decode()` 方法进行解码即可得到相应的数据，虽然解码方式可能和原有编码方式不一致\n",
    "\n",
    "#### `dectect()` 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'EUC-JP', 'confidence': 0.99, 'language': 'Japanese'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'この文はテストに使用される文です'.encode('euc-jp')\n",
    "chardet.detect(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'この文はテストに使用される文です'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.decode(\"EUC-JP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'GB2312', 'confidence': 0.99, 'language': 'Chinese'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data='这个句子是用于测试的语句'.encode('gbk')\n",
    "chardet.detect(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'这个句子是用于测试的语句'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decode the data\n",
    "data.decode(\"gb2312\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'Big5', 'confidence': 0.99, 'language': 'Chinese'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data='這個語句是用於測試的語句'.encode('Big5')\n",
    "chardet.detect(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'ISO-8859-1', 'confidence': 0.73, 'language': ''}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=\"Cette phrase est la déclaration utilisée pour tester\".encode(\"windows-1252\")\n",
    "chardet.detect(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cette phrase est la déclaration utilisée pour tester'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 解码文件\n",
    "data.decode(\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context is:\n",
      "\t b'\\xa4\\xb3\\xa4\\xce\\xca\\xb8\\xa4\\xcf\\xa5\\xc6\\xa5\\xb9\\xa5\\xc8\\xa4\\xcb\\xbb\\xc8\\xcd\\xd1\\xa4\\xb5\\xa4\\xec\\xa4\\xeb\\xca\\xb8\\xa4\\xc7\\xa4\\xb9\\xa1\\xa3\\xa4\\xb3\\xa4\\xec\\xa4\\xcf\\xc6\\xfc\\xcb\\xdc\\xb8\\xec\\xa4\\xce\\xa5\\xc6\\xa5\\xad\\xa5\\xb9\\xa5\\xc8\\xa4\\xc7\\xa4\\xb9\\n\\xa4\\xb3\\xa4\\xce\\xca\\xb8\\xa4\\xcf\\xa5\\xc6\\xa5\\xb9\\xa5\\xc8\\xa4\\xcb\\xbb\\xc8\\xcd\\xd1\\xa4\\xb5\\xa4\\xec\\xa4\\xeb\\xca\\xb8\\xa4\\xc7\\xa4\\xb9\\xa1\\xa3\\xa4\\xb3\\xa4\\xec\\xa4\\xcf\\xc6\\xfc\\xcb\\xdc\\xb8\\xec\\xa4\\xce\\xa5\\xc6\\xa5\\xad\\xa5\\xb9\\xa5\\xc8\\xa4\\xc7\\xa4\\xb9\\n\\xa4\\xb3\\xa4\\xce\\xca\\xb8\\xa4\\xcf\\xa5\\xc6\\xa5\\xb9\\xa5\\xc8\\xa4\\xcb\\xbb\\xc8\\xcd\\xd1\\xa4\\xb5\\xa4\\xec\\xa4\\xeb\\xca\\xb8\\xa4\\xc7\\xa4\\xb9\\xa1\\xa3\\xa4\\xb3\\xa4\\xec\\xa4\\xcf\\xc6\\xfc\\xcb\\xdc\\xb8\\xec\\xa4\\xce\\xa5\\xc6\\xa5\\xad\\xa5\\xb9\\xa5\\xc8\\xa4\\xc7\\xa4\\xb9\\n\\xa4\\xb3\\xa4\\xce\\xca\\xb8\\xa4\\xcf\\xa5\\xc6\\xa5\\xb9\\xa5\\xc8\\xa4\\xcb\\xbb\\xc8\\xcd\\xd1\\xa4\\xb5\\xa4\\xec\\xa4\\xeb\\xca\\xb8\\xa4\\xc7\\xa4\\xb9\\xa1\\xa3\\xa4\\xb3\\xa4\\xec\\xa4\\xcf\\xc6\\xfc\\xcb\\xdc\\xb8\\xec\\xa4\\xce\\xa5\\xc6\\xa5\\xad\\xa5\\xb9\\xa5\\xc8\\xa4\\xc7\\xa4\\xb9\\n'\n",
      "Char encoding:\n",
      "\t {'encoding': 'EUC-JP', 'confidence': 1.0, 'language': 'Japanese'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/jp.txt\", \"br\") as file:\n",
    "    data = file.read()\n",
    "    print(\"Context is:\\n\\t\", data)\n",
    "    print(\"Char encoding:\\n\\t\", chardet.detect(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'この文はテストに使用される文です。これは日本語のテキストです\\nこの文はテストに使用される文です。これは日本語のテキストです\\nこの文はテストに使用される文です。これは日本語のテキストです\\nこの文はテストに使用される文です。これは日本語のテキストです\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.decode('EUC-JP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `UniversalDetector`\n",
    "它是一个类，可以调用 `reset()` 方法将对象重置，之后通过 `feed()` 方法接收二进制数据进行检测，完成之后可以使用 `close()` 停止分析文件并对文件编码类型进行预测。通过 `result` 属性可以得到文件编码信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 glob 库来搜索文件\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/jp.txt\n",
      "{'encoding': 'EUC-JP', 'confidence': 1.0, 'language': 'Japanese'}\n",
      "./data/jp_copy.txt\n",
      "{'encoding': 'EUC-JP', 'confidence': 1.0, 'language': 'Japanese'}\n"
     ]
    }
   ],
   "source": [
    "# 初始化类\n",
    "detector = UniversalDetector()\n",
    "\n",
    "# 得到文件名\n",
    "for filename in glob.glob('./data/*.txt'):\n",
    "    print(filename)\n",
    "    detector.reset()\n",
    "    for line in open(filename, 'br'):\n",
    "        detector.feed(line)\n",
    "        if detector.done: break\n",
    "    detector.close()\n",
    "    \n",
    "    # 调用 result 属性得到相应的结果\n",
    "    print(detector.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "この文はテストに使用される文です。これは日本語のテキストです\n",
      "この文はテストに使用される文です。これは日本語のテキストです\n",
      "この文はテストに使用される文です。これは日本語のテキストです\n",
      "この文はテストに使用される文です。これは日本語のテキストです\n",
      "This is test line 1\n",
      "This is test line 2\n"
     ]
    }
   ],
   "source": [
    "with open(filename, \"r\", encoding=\"EUC-JP\") as file:\n",
    "    print(file.read())\n",
    "#     for i in file.readlines():\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xa4\\xb3\\xa4\\xce\\xca\\xb8\\xa4\\xcf\\xa5\\xc6\\xa5\\xb9\\xa5\\xc8\\xa4\\xcb\\xbb\\xc8\\xcd\\xd1\\xa4\\xb5\\xa4\\xec\\xa4\\xeb\\xca\\xb8\\xa4\\xc7\\xa4\\xb9\\xa1\\xa3\\xa4\\xb3\\xa4\\xec\\xa4\\xcf\\xc6\\xfc\\xcb\\xdc\\xb8\\xec\\xa4\\xce\\xa5\\xc6\\xa5\\xad\\xa5\\xb9\\xa5\\xc8\\xa4\\xc7\\xa4\\xb9\\n\\xa4\\xb3\\xa4\\xce\\xca\\xb8\\xa4\\xcf\\xa5\\xc6\\xa5\\xb9\\xa5\\xc8\\xa4\\xcb\\xbb\\xc8\\xcd\\xd1\\xa4\\xb5\\xa4\\xec\\xa4\\xeb\\xca\\xb8\\xa4\\xc7\\xa4\\xb9\\xa1\\xa3\\xa4\\xb3\\xa4\\xec\\xa4\\xcf\\xc6\\xfc\\xcb\\xdc\\xb8\\xec\\xa4\\xce\\xa5\\xc6\\xa5\\xad\\xa5\\xb9\\xa5\\xc8\\xa4\\xc7\\xa4\\xb9\\n\\xa4\\xb3\\xa4\\xce\\xca\\xb8\\xa4\\xcf\\xa5\\xc6\\xa5\\xb9\\xa5\\xc8\\xa4\\xcb\\xbb\\xc8\\xcd\\xd1\\xa4\\xb5\\xa4\\xec\\xa4\\xeb\\xca\\xb8\\xa4\\xc7\\xa4\\xb9\\xa1\\xa3\\xa4\\xb3\\xa4\\xec\\xa4\\xcf\\xc6\\xfc\\xcb\\xdc\\xb8\\xec\\xa4\\xce\\xa5\\xc6\\xa5\\xad\\xa5\\xb9\\xa5\\xc8\\xa4\\xc7\\xa4\\xb9\\n\\xa4\\xb3\\xa4\\xce\\xca\\xb8\\xa4\\xcf\\xa5\\xc6\\xa5\\xb9\\xa5\\xc8\\xa4\\xcb\\xbb\\xc8\\xcd\\xd1\\xa4\\xb5\\xa4\\xec\\xa4\\xeb\\xca\\xb8\\xa4\\xc7\\xa4\\xb9\\xa1\\xa3\\xa4\\xb3\\xa4\\xec\\xa4\\xcf\\xc6\\xfc\\xcb\\xdc\\xb8\\xec\\xa4\\xce\\xa5\\xc6\\xa5\\xad\\xa5\\xb9\\xa5\\xc8\\xa4\\xc7\\xa4\\xb9\\nThis is test line 1\\nThis is test line 2'\n"
     ]
    }
   ],
   "source": [
    "with open(filename, \"br\") as file:\n",
    "    print(file.read())\n",
    "#     for i in file.readlines():\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考\n",
    "1. [chardet 3.0.4 documentation](https://chardet.readthedocs.io/en/latest/usage.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
